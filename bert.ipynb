{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install bert-extractive-summarizer\n",
    "%pip install --upgrade transformers\n",
    "%pip install --upgrade bert-extractive-summarizer\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category filename                              title  \\\n",
       "0  business  001.txt  Ad sales boost Time Warner profit   \n",
       "1  business  002.txt   Dollar gains on Greenspan speech   \n",
       "2  business  003.txt  Yukos unit buyer faces loan claim   \n",
       "3  business  004.txt  High fuel prices hit BA's profits   \n",
       "4  business  005.txt  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                             content  \n",
       "0   Quarterly profits at US media giant TimeWarne...  \n",
       "1   The dollar has hit its highest level against ...  \n",
       "2   The owners of embattled Russian oil giant Yuk...  \n",
       "3   British Airways has blamed high fuel prices f...  \n",
       "4   Shares in UK drinks and food firm Allied Dome...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load & check Data\n",
    "import pandas as pd\n",
    "\n",
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data = pd.read_csv(\n",
    "        'drive/My Drive/COMP SCI 539/bbc-news-data.csv', delimiter='\\t')\n",
    "else:\n",
    "    data = pd.read_csv('bbc-news-data.csv', delimiter='\\t')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category    0\n",
      "filename    0\n",
      "title       0\n",
      "content     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Find and remove nulls\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Data to lowercase\n",
    "data[\"title\"] = data[\"title\"].str.lower()\n",
    "data[\"content\"] = data[\"content\"].str.lower()\n",
    "# Remove and replace contractions\n",
    "# Find more contraction in text and add\n",
    "contraction_dict = {\"can't\": \"cannot\", \"didn't\": \"did not\", \"aren't\": \"are not\", \"she'd\": \"she would\", \"he'd\": \"he would\", \"they'd\": \"they would\", \"they've\": \"they have\",\n",
    "                    \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"she'll\": \"she will\", \"he'll\": \"he will\", \"they'll\": \"they will\"\n",
    "                    }\n",
    "\n",
    "\n",
    "def contraction_replacer(text):\n",
    "    for word in text.split():\n",
    "        if word in contraction_dict:\n",
    "            text = text.replace(word, contraction_dict[word])\n",
    "    return text\n",
    "\n",
    "\n",
    "data[\"title\"] = data[\"title\"].apply(contraction_replacer)\n",
    "data[\"content\"] = data[\"content\"].apply(contraction_replacer)\n",
    "\n",
    "# Remove punctuation and numbers\n",
    "# Find more punctuation in text and add\n",
    "\n",
    "numbers = '0123456789'\n",
    "\n",
    "\n",
    "def punctuation_numbers_remover(text):\n",
    "    for number in numbers:\n",
    "        text = text.replace(number, '')\n",
    "    return text\n",
    "\n",
    "\n",
    "data[\"title\"] = data[\"title\"].apply(punctuation_numbers_remover)\n",
    "data[\"content\"] = data[\"content\"].apply(punctuation_numbers_remover)\n",
    "\n",
    "data.head()\n",
    "\n",
    "content_lengths = [len(content.split()) for content in data[\"content\"]]\n",
    "\n",
    "# remove the outliers\n",
    "MAX_CONTENT_LENGTH = 1000\n",
    "MAX_TITLE_LENGTH = 10\n",
    "# get the indices of the documents that have more than 1000 words\n",
    "outliers = [idx for idx, length in enumerate(\n",
    "    content_lengths) if length > MAX_CONTENT_LENGTH]\n",
    "\n",
    "# remove the outliers from the data\n",
    "data = data.drop(outliers, axis=0).reset_index(drop=True)\n",
    "\n",
    "content_lengths = [len(content.split()) for content in data[\"content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 499/500\r"
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create a BERT Summarizer\n",
    "bert_model = Summarizer()\n",
    "predictions = []\n",
    "\n",
    "\n",
    "for i in range(500):\n",
    "       print(f'Article {i}/{500}', end='\\r')\n",
    "       # Summarize the content\n",
    "       summary = bert_model(data[\"content\"][i], num_sentences=1)\n",
    "       # Add the summary to the predictions list\n",
    "       predictions.append(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1:  0.22259510941951052\n",
      "ROUGE-L:  0.18755025677527778\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "# Evaluation\n",
    "\n",
    "rouge1 = 0.0\n",
    "rougeL = 0.0\n",
    "\n",
    "def calculate_rouge(reference, generated):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, generated)\n",
    "    return scores\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    sc = calculate_rouge(data[\"title\"][i], predictions[i])\n",
    "    rouge1 += sc[\"rouge1\"].fmeasure\n",
    "    rougeL += sc[\"rougeL\"].fmeasure\n",
    "\n",
    "rouge1 /= len(predictions)\n",
    "rougeL /= len(predictions)\n",
    "\n",
    "print(\"ROUGE-1: \", rouge1)\n",
    "print(\"ROUGE-L: \", rougeL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
